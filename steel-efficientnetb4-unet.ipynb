{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'test_images',\n",
       " 'test_images.zip',\n",
       " 'train.csv',\n",
       " 'train_images',\n",
       " 'train_images.zip']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./severstal-steel-defect-detection/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# import data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import image utils\n",
    "import PIL\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "\n",
    "# import image processing\n",
    "import scipy.ndimage as ndi\n",
    "import scipy\n",
    "\n",
    "# import image utilities\n",
    "from skimage.morphology import binary_opening, disk, label, binary_closing\n",
    "\n",
    "# import image augmentation\n",
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, Flip, OneOf, Compose, PadIfNeeded, RandomContrast, RandomGamma, RandomBrightness, ElasticTransform,\n",
    "    NoOp, RandomSizedCrop, RGBShift, VerticalFlip, RandomRotate90, Normalize, Resize, CropNonEmptyMaskIfExists\n",
    ")\n",
    "from albumentations.pytorch.transforms import ToTensor\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, Sampler\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import cv2\n",
    "from skimage.morphology import binary_opening, disk, label\n",
    "\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = './severstal-steel-defect-detection/train_images/'\n",
    "TEST_PATH = './severstal-steel-defect-detection/test_images/'\n",
    "\n",
    "train = pd.read_csv('./severstal-steel-defect-detection/train.csv')\n",
    "\n",
    "\n",
    "train_transforms = [\n",
    "    OneOf([\n",
    "        ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1,\n",
    "                         rotate_limit=15,\n",
    "                         border_mode=cv2.BORDER_CONSTANT),\n",
    "        OpticalDistortion(distort_limit=0.11, shift_limit=0.15,\n",
    "                          border_mode=cv2.BORDER_CONSTANT),\n",
    "        ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        NoOp()]),\n",
    "    RandomSizedCrop(min_max_height=(100, 256),\n",
    "                    height=256,\n",
    "                    width=1600, p=0.3),\n",
    "    HorizontalFlip(p=0.5),\n",
    "    VerticalFlip(p=0.5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002cc93b.jpg_4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00031f466.jpg_1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
       "1  0002cc93b.jpg_2                                                NaN\n",
       "2  0002cc93b.jpg_3                                                NaN\n",
       "3  0002cc93b.jpg_4                                                NaN\n",
       "4  00031f466.jpg_1                                                NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./severstal-steel-defect-detection/train.csv')\n",
    "# https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
    "df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n",
    "df['ClassId'] = df['ClassId'].astype(int)\n",
    "df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
    "df['defects'] = df.count(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ClassId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00031f466.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>000418bfc.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>000789191.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0007a71bf.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18661 28 18863 82 19091 110 19347 110 19603 11...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ClassId                                                        1    2  \\\n",
       "ImageId                                                                 \n",
       "0002cc93b.jpg  29102 12 29346 24 29602 24 29858 24 30114 24 3...  NaN   \n",
       "00031f466.jpg                                                NaN  NaN   \n",
       "000418bfc.jpg                                                NaN  NaN   \n",
       "000789191.jpg                                                NaN  NaN   \n",
       "0007a71bf.jpg                                                NaN  NaN   \n",
       "\n",
       "ClassId                                                        3    4  defects  \n",
       "ImageId                                                                         \n",
       "0002cc93b.jpg                                                NaN  NaN        1  \n",
       "00031f466.jpg                                                NaN  NaN        0  \n",
       "000418bfc.jpg                                                NaN  NaN        0  \n",
       "000789191.jpg                                                NaN  NaN        0  \n",
       "0007a71bf.jpg  18661 28 18863 82 19091 110 19347 110 19603 11...  NaN        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 -> mask, 0 -> background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def make_mask(row_id, df):\n",
    "    '''Given a row index, return image_id and mask (256, 1600, 4) from the dataframe `df`'''\n",
    "    fname = df.iloc[row_id].name\n",
    "    labels = df.iloc[row_id][:4]\n",
    "    masks = np.zeros((256, 1600, 4), dtype=np.float32) # float32 is V.Imp\n",
    "    # 4:class 1～4 (ch:0～3)\n",
    "\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            mask = np.zeros(256 * 1600, dtype=np.uint8)\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask[pos:(pos + le)] = 1\n",
    "            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n",
    "    return fname, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(transforms, mean, std):\n",
    "    list_transforms = []\n",
    "    \n",
    "    if transforms != None:\n",
    "        list_transforms.extend(transforms)\n",
    "        \n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            CropNonEmptyMaskIfExists(128,800),\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "    \n",
    "\n",
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, df, data_folder, transforms, mean, std):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.transforms = get_transforms(transforms, mean, std)\n",
    "        self.fnames = self.df.index.tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id, mask = make_mask(idx, self.df)\n",
    "        image_path = os.path.join(self.root, \"train_images\",  image_id)\n",
    "        img = np.asarray(Image.open(image_path))\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask'] # 1x256x1600x4\n",
    "        mask = mask[0].permute(2, 0, 1) # 1x4x256x1600\n",
    "        \n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "test_split = 0.2\n",
    "batch_size = 8\n",
    "epochs = 30\n",
    "learning_rate = 0.001\n",
    "num_workers = 0\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and data loaders (for FISH)\n",
    "train_ds = SteelDataset(df, data_folder='./severstal-steel-defect-detection/', \n",
    "                        transforms=train_transforms, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "test_ds = SteelDataset(df, data_folder='./severstal-steel-defect-detection/', \n",
    "                        transforms=None, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "\n",
    "dataset_size = len(train_ds)\n",
    "\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(test_split * dataset_size))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "testloader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, sampler=test_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:            \n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://www.kaggle.com/wh1tezzz/correct-dice-metrics-for-this-competition\n",
    "\n",
    "def dice_channel_torch(probability, truth, threshold):\n",
    "    batch_size = truth.shape[0]\n",
    "    channel_num = truth.shape[1]\n",
    "    mean_dice_channel = 0.\n",
    "    with torch.no_grad():\n",
    "        for i in range(batch_size):\n",
    "            for j in range(channel_num):\n",
    "                channel_dice = dice_single_channel(probability[i, j,:,:], truth[i, j, :, :], threshold)\n",
    "                mean_dice_channel += channel_dice/(batch_size * channel_num)\n",
    "    return mean_dice_channel\n",
    "\n",
    "\n",
    "def dice_single_channel(probability, truth, threshold, eps = 1E-9):\n",
    "    p = (probability.view(-1) > threshold).float()\n",
    "    t = (truth.view(-1) > 0.5).float()\n",
    "    dice = (2.0 * (p * t).sum() + eps)/ (p.sum() + t.sum() + eps)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(output, target):\n",
    "    smooth = 1e-5\n",
    "\n",
    "    if torch.is_tensor(output):\n",
    "        output = torch.sigmoid(output).data.cpu().numpy()\n",
    "    if torch.is_tensor(target):\n",
    "        target = target.data.cpu().numpy()\n",
    "    output_ = output > 0.5\n",
    "    target_ = target > 0.5\n",
    "    intersection = (output_ & target_).sum()\n",
    "    union = (output_ | target_).sum()\n",
    "\n",
    "    return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCESoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True, w1=1, w2=1):\n",
    "        super(BCESoftDiceLoss, self).__init__()\n",
    "        self.bce_loss = nn.BCELoss(weight, size_average)\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        # BCELoss2d\n",
    "        probs        = torch.sigmoid(logits)\n",
    "        probs_flat   = probs.view (-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "        bce_loss = self.bce_loss(probs_flat, targets_flat)\n",
    "        \n",
    "        # SoftDiceLoss\n",
    "        num = targets.size(0)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        m1  = probs.view(num,-1)\n",
    "        m2  = targets.view(num,-1)\n",
    "        intersection = (m1 * m2)\n",
    "\n",
    "        score = 2. * (intersection.sum(1)+1) / (m1.sum(1) + m2.sum(1)+1)\n",
    "        soft_dice_loss = 1- score.sum()/num\n",
    "        \n",
    "        return self.w1 * bce_loss + self.w2 * soft_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        bce = F.binary_cross_entropy_with_logits(input, target)\n",
    "        smooth = 1e-5\n",
    "        input = torch.sigmoid(input)\n",
    "        num = target.size(0)\n",
    "        input = input.view(num, -1)\n",
    "        target = target.view(num, -1)\n",
    "        intersection = (input * target)\n",
    "        dice = (2. * intersection.sum(1) + smooth) / (input.sum(1) + target.sum(1) + smooth)\n",
    "        dice = 1 - dice.sum() / num\n",
    "        return 0.5 * bce + dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lovasz-Softmax and Jaccard hinge loss in PyTorch\n",
    "Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n",
    "\n",
    "Source:\n",
    "https://github.com/bermanmaxim/LovaszSoftmax/blob/master/pytorch/lovasz_losses.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "try:\n",
    "    from itertools import  ifilterfalse\n",
    "except ImportError: # py3k\n",
    "    from itertools import  filterfalse as ifilterfalse\n",
    "\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1: # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def iou_binary(preds, labels, EMPTY=1., ignore=None, per_image=True):\n",
    "    \"\"\"\n",
    "    IoU for foreground class\n",
    "    binary: 1 foreground, 0 background\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        intersection = ((label == 1) & (pred == 1)).sum()\n",
    "        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n",
    "        if not union:\n",
    "            iou = EMPTY\n",
    "        else:\n",
    "            iou = float(intersection) / float(union)\n",
    "        ious.append(iou)\n",
    "    iou = mean(ious)    # mean accross images if per_image\n",
    "    return 100 * iou\n",
    "\n",
    "\n",
    "def iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\n",
    "    \"\"\"\n",
    "    Array of IoU for each (non ignored) class\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        iou = []\n",
    "        for i in range(C):\n",
    "            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n",
    "                intersection = ((label == i) & (pred == i)).sum()\n",
    "                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n",
    "                if not union:\n",
    "                    iou.append(EMPTY)\n",
    "                else:\n",
    "                    iou.append(float(intersection) / float(union))\n",
    "        ious.append(iou)\n",
    "    ious = [mean(iou) for iou in zip(*ious)] # mean accross images if per_image\n",
    "    return 100 * np.array(ious)\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n",
    "                          for log, lab in zip(logits, labels))\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return logits.sum() * 0.\n",
    "    signs = 2. * labels.float() - 1.\n",
    "    errors = (1. - logits * Variable(signs))\n",
    "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "    perm = perm.data\n",
    "    gt_sorted = labels[perm]\n",
    "    grad = lovasz_grad(gt_sorted)\n",
    "    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = scores.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = (labels != ignore)\n",
    "    vscores = scores[valid]\n",
    "    vlabels = labels[valid]\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "class StableBCELoss(torch.nn.modules.Module):\n",
    "    def __init__(self):\n",
    "         super(StableBCELoss, self).__init__()\n",
    "    def forward(self, input, target):\n",
    "        neg_abs = - input.abs()\n",
    "        loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "def binary_xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Cross entropy loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    logits, labels = flatten_binary_scores(logits, labels, ignore)\n",
    "    loss = StableBCELoss()(logits, Variable(labels.float()))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# --------------------------- MULTICLASS LOSSES ---------------------------\n",
    "\n",
    "class LovaszSoftmaxLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Class wrapper for lovasz_softmax loss function.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LovaszSoftmaxLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input = F.softmax(input, dim = 1)\n",
    "        \n",
    "        b, c, h, w = target.size()\n",
    "        labels = torch.zeros(b,h,w)\n",
    "        \n",
    "        for i in range(1, c+1):\n",
    "            labels += (target * i)[:,i-1,:,:]\n",
    "        \n",
    "        return lovasz_softmax(input, labels, classes='all')\n",
    "\n",
    "def lovasz_softmax(probas, labels, classes='present', per_image=False, ignore=None):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1).\n",
    "              Interpreted as binary (sigmoid) output with outputs of size [B, H, W].\n",
    "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class labels\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), classes=classes)\n",
    "                          for prob, lab in zip(probas, labels))\n",
    "    else:\n",
    "        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), classes=classes)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, classes='present'):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "    \"\"\"\n",
    "    if probas.numel() == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return probas * 0.\n",
    "    C = probas.size(1)\n",
    "    losses = []\n",
    "    class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes\n",
    "    for c in class_to_sum:\n",
    "        fg = (labels == c).float() # foreground for class c\n",
    "        if (classes is 'present' and fg.sum() == 0):\n",
    "            continue\n",
    "        if C == 1:\n",
    "            if len(classes) > 1:\n",
    "                raise ValueError('Sigmoid output possible only with 1 class')\n",
    "            class_pred = probas[:, 0]\n",
    "        else:\n",
    "            class_pred = probas[:, c]\n",
    "        errors = (Variable(fg) - class_pred).abs()\n",
    "        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n",
    "        perm = perm.data\n",
    "        fg_sorted = fg[perm]\n",
    "        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n",
    "    return mean(losses)\n",
    "\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch\n",
    "    \"\"\"\n",
    "    if probas.dim() == 3:\n",
    "        # assumes output of a sigmoid layer\n",
    "        B, H, W = probas.size()\n",
    "        probas = probas.view(B, 1, H, W)\n",
    "    B, C, H, W = probas.size()\n",
    "    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return probas, labels\n",
    "    valid = (labels != ignore)\n",
    "    vprobas = probas[valid.nonzero().squeeze()]\n",
    "    vlabels = labels[valid]\n",
    "    return vprobas, vlabels\n",
    "\n",
    "def xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Cross entropy loss\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(logits, Variable(labels), ignore_index=255)\n",
    "\n",
    "\n",
    "# --------------------------- HELPER FUNCTIONS ---------------------------\n",
    "def isnan(x):\n",
    "    return x != x\n",
    "\n",
    "\n",
    "def mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise ValueError('Empty mean')\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_name = 'efficientnet-b4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FPN(\n",
       "  (encoder): EfficientNetEncoder(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (23): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (24): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (25): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (26): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (27): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (28): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (29): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (30): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (31): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2688, 112, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          112, 2688, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder): FPNDecoder(\n",
       "    (conv1): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (p4): FPNBlock(\n",
       "      (skip_conv): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p3): FPNBlock(\n",
       "      (skip_conv): Conv2d(56, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p2): FPNBlock(\n",
       "      (skip_conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (s5): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s4): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s3): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s2): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.2, inplace=True)\n",
       "    (final_conv): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smp.FPN(encoder_name, encoder_weights=\"imagenet\", classes=4, activation=None)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = RAdam(model.parameters(), lr=learning_rate)\n",
    "criterion = BCEDiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = pd.DataFrame(columns = ['Epoch', \n",
    "                                      'Time per epoch', \n",
    "                                      'Avg time per step', \n",
    "                                      'Train loss',\n",
    "                                      'DICE Train',\n",
    "                                      'Test loss',\n",
    "                                     'DICE Test',\n",
    "                                     'IOU Test']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, trainloader, testloader, epochs, criterion, optimizer, train_stats):\n",
    "    #train the model\n",
    "    model = model.to(device)\n",
    "    \n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.15, patience=2)\n",
    "\n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    dice_train = 0\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        train_accuracy = 0\n",
    "        dice_train = 0\n",
    "        iou_train = 0\n",
    "        \n",
    "        for inputs, labels in tqdm_notebook(trainloader):\n",
    "            steps += 1\n",
    "            # Move input and label tensors to the default device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logps = model.forward(inputs)\n",
    "\n",
    "            loss = criterion(logps, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            dice_train += dice_channel_torch(logps, labels, threshold)\n",
    "            \n",
    "            #iou_train += iou_score(logps, labels)\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "\n",
    "        test_loss = 0\n",
    "        dice_test = 0\n",
    "        iou_test = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                logps = model.forward(inputs)\n",
    "                batch_loss = criterion(logps, labels)\n",
    "\n",
    "                test_loss += batch_loss.item()\n",
    "\n",
    "                # Calculate DICE\n",
    "                dice_test += dice_channel_torch(logps, labels, threshold)\n",
    "                \n",
    "                iou_test += iou_score(logps, labels)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "              f\"Time per epoch: {time_elapsed:.4f}.. \"\n",
    "              f\"Average time per step: {time_elapsed/len(trainloader):.4f}.. \"\n",
    "              f\"Train loss: {running_loss/len(trainloader):.4f}.. \"\n",
    "              f\"Test loss: {test_loss/len(testloader):.4f}.. \"\n",
    "              f\"DICE Train: {dice_train/len(trainloader):.4f}.. \"\n",
    "              f\"DICE Test: {dice_test/len(testloader):.4f}.. \"\n",
    "              #f\"IOU Train: {iou_train/len(trainloader):.4f}.. \"\n",
    "              f\"IOU Test: {iou_test/len(testloader):.4f}.. \"\n",
    "             )\n",
    "\n",
    "        train_stats = train_stats.append({'Epoch': epoch + 1, \n",
    "                                          'Time per epoch':time_elapsed, \n",
    "                                          'Avg time per step': time_elapsed/len(trainloader), \n",
    "                                          'Train loss' : running_loss/len(trainloader),\n",
    "                                          'Test loss' : test_loss/len(testloader),\n",
    "                                          'DICE Train' : dice_train/len(trainloader),\n",
    "                                          'DICE Test' : dice_test/len(testloader),\n",
    "                                          'IOU Test' : iou_test/len(testloader)\n",
    "                                         }, \n",
    "                                         ignore_index=True)\n",
    "                \n",
    "        scheduler.step(test_loss/len(testloader))\n",
    "        running_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "    return model, train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c1c0ee038f4ef28e5f50daa6b71a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/30.. Time per epoch: 1003.3749.. Average time per step: 0.7982.. Train loss: 0.8381.. Test loss: 0.6996.. DICE Train: 0.7512.. DICE Test: 0.8379.. IOU Test: 0.4461.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8b4913c0c4446ea6cda72bb54ea14f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/30.. Time per epoch: 1367.1655.. Average time per step: 1.0876.. Train loss: 0.8037.. Test loss: 0.7046.. DICE Train: 0.7799.. DICE Test: 0.8404.. IOU Test: 0.4235.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296d41752b4843eda84ec680d843eca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/30.. Time per epoch: 2298.8721.. Average time per step: 1.8289.. Train loss: 0.7966.. Test loss: 0.6960.. DICE Train: 0.7764.. DICE Test: 0.7534.. IOU Test: 0.4177.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7bc7ade65c43339a475e0dbf69f434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/30.. Time per epoch: 1535.5912.. Average time per step: 1.2216.. Train loss: 0.7835.. Test loss: 0.6904.. DICE Train: 0.7981.. DICE Test: 0.8416.. IOU Test: 0.4397.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0269d38eb0dc4efc9366a1fe5d9edf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/30.. Time per epoch: 2712.2861.. Average time per step: 2.1577.. Train loss: 0.7736.. Test loss: 0.6679.. DICE Train: 0.8140.. DICE Test: 0.8721.. IOU Test: 0.5185.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7d4208f17743f899d3f35aa8a27de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/30.. Time per epoch: 1539.9325.. Average time per step: 1.2251.. Train loss: 0.7722.. Test loss: 0.6578.. DICE Train: 0.8047.. DICE Test: 0.8478.. IOU Test: 0.5068.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61f51a7eccd420bbf31111ae41a45cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/30.. Time per epoch: 1560.5426.. Average time per step: 1.2415.. Train loss: 0.7648.. Test loss: 0.6613.. DICE Train: 0.8118.. DICE Test: 0.8322.. IOU Test: 0.4262.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7a8cbc9b114d7e87c352a9eed6e3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/30.. Time per epoch: 1603.5558.. Average time per step: 1.2757.. Train loss: 0.7602.. Test loss: 0.6544.. DICE Train: 0.8167.. DICE Test: 0.8820.. IOU Test: 0.5252.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48cb26edcc0438cbf93da7fa9ea577a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/30.. Time per epoch: 1496.8420.. Average time per step: 1.1908.. Train loss: 0.7499.. Test loss: 0.6449.. DICE Train: 0.8398.. DICE Test: 0.8750.. IOU Test: 0.5360.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933a489dad2943728a53de64be6e085c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/30.. Time per epoch: 1499.8623.. Average time per step: 1.1932.. Train loss: 0.7306.. Test loss: 0.6199.. DICE Train: 0.8653.. DICE Test: 0.9067.. IOU Test: 0.6010.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa20774629f47c6b1ef93e532d48434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/30.. Time per epoch: 1500.2033.. Average time per step: 1.1935.. Train loss: 0.7246.. Test loss: 0.6164.. DICE Train: 0.8758.. DICE Test: 0.9071.. IOU Test: 0.5994.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fbbe35f71304fa6b0a78fd4809b769c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "model, train_stats = train_model(model, device, trainloader, testloader, epochs, criterion, optimizer, train_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'efficientnet_b4_dice_' + str(epochs) + '.pth'\n",
    "\n",
    "checkpoint = {'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training stats\n",
    "train_stats.to_csv('efficientnet_b4_bcedice_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_stats['Test loss'], label=\"test\")\n",
    "plt.plot(train_stats['Train loss'], label=\"train\")\n",
    "plt.ylim(0, 1.4)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_stats['DICE Train'], label=\"test\")\n",
    "plt.plot(train_stats['DICE Test'], label=\"train\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"dice\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9686cc7ed0014c6da25ca1835675a577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=315), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "dice_test = 0\n",
    "iou = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm_notebook(testloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logps = model.forward(inputs)\n",
    "        batch_loss = criterion(logps, labels)\n",
    "\n",
    "        test_loss += batch_loss.item()\n",
    "\n",
    "        # Calculate DICE\n",
    "        dice_test += dice_channel_torch(logps, labels, threshold)\n",
    "        \n",
    "        iou += iou_score(logps, labels)\n",
    "        \n",
    "test_loss = test_loss / len(testloader)\n",
    "dice_test = dice_test / len(testloader)\n",
    "iou = iou / len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.19616832107542054\n",
      "DICE test: 0.9488622546195984\n",
      "IOU test: 0.627276287755503\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: {}'.format(test_loss))\n",
    "print('DICE test: {}'.format(dice_test))\n",
    "print('IOU test: {}'.format(iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FPN(\n",
       "  (encoder): EfficientNetEncoder(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (23): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (24): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (25): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (26): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (27): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (28): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (29): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (30): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (31): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2688, 112, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          112, 2688, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder): FPNDecoder(\n",
       "    (conv1): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (p4): FPNBlock(\n",
       "      (skip_conv): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p3): FPNBlock(\n",
       "      (skip_conv): Conv2d(56, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p2): FPNBlock(\n",
       "      (skip_conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (s5): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s4): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s3): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s2): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.2, inplace=True)\n",
       "    (final_conv): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    '''Dataset for test prediction'''\n",
    "    def __init__(self, root, df, mean, std):\n",
    "        self.root = root\n",
    "        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "        self.fnames = df['ImageId'].unique().tolist()\n",
    "        self.num_samples = len(self.fnames)\n",
    "        self.transform = Compose(\n",
    "            [\n",
    "                Normalize(mean=mean, std=std, p=1),\n",
    "                ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        path = os.path.join(self.root, fname)\n",
    "        image = cv2.imread(path)\n",
    "        images = self.transform(image=image)[\"image\"]\n",
    "        return fname, images\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "sample_submission_path = './severstal-steel-defect-detection/sample_submission.csv'\n",
    "test_data_folder = TEST_PATH\n",
    "df = pd.read_csv(sample_submission_path)\n",
    "testset = DataLoader(\n",
    "    TestDataset(test_data_folder, df, mean, std),\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(probability, threshold, min_size):\n",
    "    '''Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored'''\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((256, 1600), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6623619ee1d04701be3f4095a06672dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=901), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_threshold = threshold\n",
    "min_size = 3500\n",
    "\n",
    "# start prediction\n",
    "predictions = []\n",
    "for i, batch in enumerate(tqdm_notebook(testset)):\n",
    "    fnames, images = batch\n",
    "    batch_preds = torch.sigmoid(model(images.to(device)))\n",
    "    batch_preds = batch_preds.detach().cpu().numpy()\n",
    "    for fname, preds in zip(fnames, batch_preds):\n",
    "        for cls, pred in enumerate(preds):\n",
    "            pred, num = post_process(pred, best_threshold, min_size)\n",
    "            rle = mask2rle(pred)\n",
    "            name = fname + f\"_{cls+1}\"\n",
    "            predictions.append([name, rle])\n",
    "\n",
    "# save predictions to submission.csv\n",
    "df = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\n",
    "df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>004f40c73.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>004f40c73.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>004f40c73.jpg_3</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>004f40c73.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>006f39c41.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId EncodedPixels\n",
       "0  004f40c73.jpg_1              \n",
       "1  004f40c73.jpg_2              \n",
       "2  004f40c73.jpg_3              \n",
       "3  004f40c73.jpg_4              \n",
       "4  006f39c41.jpg_1              "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7204"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.EncodedPixels.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
