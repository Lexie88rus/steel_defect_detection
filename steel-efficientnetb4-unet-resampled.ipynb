{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_submission.csv',\n",
       " 'test_images',\n",
       " 'test_images.zip',\n",
       " 'train.csv',\n",
       " 'train_images',\n",
       " 'train_images.zip']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./severstal-steel-defect-detection/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# import data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# import image utils\n",
    "import PIL\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "\n",
    "# import image processing\n",
    "import scipy.ndimage as ndi\n",
    "import scipy\n",
    "\n",
    "# import image utilities\n",
    "from skimage.morphology import binary_opening, disk, label, binary_closing\n",
    "\n",
    "# import image augmentation\n",
    "from albumentations import (\n",
    "    HorizontalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, RandomBrightnessContrast, IAAPiecewiseAffine,\n",
    "    IAASharpen, IAAEmboss, Flip, OneOf, Compose, PadIfNeeded, RandomContrast, RandomGamma, RandomBrightness, ElasticTransform,\n",
    "    NoOp, RandomSizedCrop, RGBShift, VerticalFlip, RandomRotate90, Normalize, Resize, CropNonEmptyMaskIfExists\n",
    ")\n",
    "from albumentations.pytorch.transforms import ToTensor\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, Sampler\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn import init\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import cv2\n",
    "from skimage.morphology import binary_opening, disk, label\n",
    "\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = './severstal-steel-defect-detection/train_images/'\n",
    "TEST_PATH = './severstal-steel-defect-detection/test_images/'\n",
    "\n",
    "train = pd.read_csv('./severstal-steel-defect-detection/train.csv')\n",
    "\n",
    "\n",
    "train_transforms = [\n",
    "    OneOf([\n",
    "        ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1,\n",
    "                         rotate_limit=15,\n",
    "                         border_mode=cv2.BORDER_CONSTANT),\n",
    "        OpticalDistortion(distort_limit=0.11, shift_limit=0.15,\n",
    "                          border_mode=cv2.BORDER_CONSTANT),\n",
    "        ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        NoOp()]),\n",
    "    RandomSizedCrop(min_max_height=(100, 256),\n",
    "                    height=256,\n",
    "                    width=1600, p=0.3),\n",
    "    HorizontalFlip(p=0.5),\n",
    "    VerticalFlip(p=0.5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0002cc93b.jpg_1</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0002cc93b.jpg_2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0002cc93b.jpg_3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0002cc93b.jpg_4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00031f466.jpg_1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels\n",
       "0  0002cc93b.jpg_1  29102 12 29346 24 29602 24 29858 24 30114 24 3...\n",
       "1  0002cc93b.jpg_2                                                NaN\n",
       "2  0002cc93b.jpg_3                                                NaN\n",
       "3  0002cc93b.jpg_4                                                NaN\n",
       "4  00031f466.jpg_1                                                NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./severstal-steel-defect-detection/train.csv')\n",
    "# https://www.kaggle.com/amanooo/defect-detection-starter-u-net\n",
    "df['ImageId'], df['ClassId'] = zip(*df['ImageId_ClassId'].str.split('_'))\n",
    "df['ClassId'] = df['ClassId'].astype(int)\n",
    "df = df.pivot(index='ImageId',columns='ClassId',values='EncodedPixels')\n",
    "df['defects'] = df.count(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ClassId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ImageId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0002cc93b.jpg</td>\n",
       "      <td>29102 12 29346 24 29602 24 29858 24 30114 24 3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>00031f466.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>000418bfc.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>000789191.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0007a71bf.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18661 28 18863 82 19091 110 19347 110 19603 11...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ClassId                                                        1    2  \\\n",
       "ImageId                                                                 \n",
       "0002cc93b.jpg  29102 12 29346 24 29602 24 29858 24 30114 24 3...  NaN   \n",
       "00031f466.jpg                                                NaN  NaN   \n",
       "000418bfc.jpg                                                NaN  NaN   \n",
       "000789191.jpg                                                NaN  NaN   \n",
       "0007a71bf.jpg                                                NaN  NaN   \n",
       "\n",
       "ClassId                                                        3    4  defects  \n",
       "ImageId                                                                         \n",
       "0002cc93b.jpg                                                NaN  NaN        1  \n",
       "00031f466.jpg                                                NaN  NaN        0  \n",
       "000418bfc.jpg                                                NaN  NaN        0  \n",
       "000789191.jpg                                                NaN  NaN        0  \n",
       "0007a71bf.jpg  18661 28 18863 82 19091 110 19347 110 19603 11...  NaN        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 -> mask, 0 -> background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def make_mask(row_id, df):\n",
    "    '''Given a row index, return image_id and mask (256, 1600, 4) from the dataframe `df`'''\n",
    "    fname = df.iloc[row_id].name\n",
    "    labels = df.iloc[row_id][:4]\n",
    "    masks = np.zeros((256, 1600, 4), dtype=np.float32) # float32 is V.Imp\n",
    "    # 4:class 1～4 (ch:0～3)\n",
    "\n",
    "    for idx, label in enumerate(labels.values):\n",
    "        if label is not np.nan:\n",
    "            label = label.split(\" \")\n",
    "            positions = map(int, label[0::2])\n",
    "            length = map(int, label[1::2])\n",
    "            mask = np.zeros(256 * 1600, dtype=np.uint8)\n",
    "            for pos, le in zip(positions, length):\n",
    "                mask[pos:(pos + le)] = 1\n",
    "            masks[:, :, idx] = mask.reshape(256, 1600, order='F')\n",
    "    return fname, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(transforms, mean, std):\n",
    "    list_transforms = []\n",
    "    \n",
    "    if transforms != None:\n",
    "        list_transforms.extend(transforms)\n",
    "        \n",
    "    list_transforms.extend(\n",
    "        [\n",
    "            CropNonEmptyMaskIfExists(128,800),\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "    \n",
    "\n",
    "class SteelDataset(Dataset):\n",
    "    def __init__(self, df, data_folder, transforms, mean, std, indices):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.transforms = get_transforms(transforms, mean, std)\n",
    "        self.fnames = self.df.index.tolist()\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = indices[idx]\n",
    "        image_id, mask = make_mask(idx, self.df)\n",
    "        image_path = os.path.join(self.root, \"train_images\",  image_id)\n",
    "        img = np.asarray(Image.open(image_path))\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask'] # 1x256x1600x4\n",
    "        mask = mask[0].permute(2, 0, 1) # 1x4x256x1600\n",
    "        \n",
    "        return img, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "test_split = 0.2\n",
    "batch_size = 8\n",
    "epochs = 10\n",
    "learning_rate = 0.00001\n",
    "num_workers = 0\n",
    "threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset and data loaders\n",
    "dataset_size = len(df)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(test_split * dataset_size))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "train_indices, test_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_ds = SteelDataset(df, data_folder='./severstal-steel-defect-detection/', \n",
    "                        transforms=train_transforms, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),\n",
    "                       indices = train_indices)\n",
    "test_ds = SteelDataset(df, data_folder='./severstal-steel-defect-detection/', \n",
    "                        transforms=None, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225),\n",
    "                      indices = test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(index):\n",
    "    vals = df.iloc[index].copy().fillna('-1')\n",
    "    if vals.defects == 0:\n",
    "        return 0\n",
    "    return np.argmax(np.where(vals != '-1', 1, 0)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = [45.4, 6.9, 1.9, 39.6, 6.2]\n",
    "cls = [get_class(c) for c in train_indices]\n",
    "\n",
    "reciprocal_weights = []\n",
    "for index in range(len(train_ds)):\n",
    "    reciprocal_weights.append(prob[cls[index]])\n",
    "\n",
    "weights = (1 / torch.Tensor(reciprocal_weights))\n",
    "train_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = [get_class(c) for c in test_indices]\n",
    "\n",
    "test_reciprocal_weights = []\n",
    "for index in range(len(test_ds)):\n",
    "    test_reciprocal_weights.append(prob[cls[index]])\n",
    "\n",
    "test_weights = (1 / torch.Tensor(test_reciprocal_weights))\n",
    "test_sampler = torch.utils.data.sampler.WeightedRandomSampler(test_weights, len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "testloader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, sampler=test_sampler, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:            \n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://www.kaggle.com/wh1tezzz/correct-dice-metrics-for-this-competition\n",
    "\n",
    "def dice_channel_torch(probability, truth, threshold):\n",
    "    batch_size = truth.shape[0]\n",
    "    channel_num = truth.shape[1]\n",
    "    mean_dice_channel = 0.\n",
    "    with torch.no_grad():\n",
    "        for i in range(batch_size):\n",
    "            for j in range(channel_num):\n",
    "                channel_dice = dice_single_channel(probability[i, j,:,:], truth[i, j, :, :], threshold)\n",
    "                mean_dice_channel += channel_dice/(batch_size * channel_num)\n",
    "    return mean_dice_channel\n",
    "\n",
    "\n",
    "def dice_single_channel(probability, truth, threshold, eps = 1E-9):\n",
    "    p = (probability.view(-1) > threshold).float()\n",
    "    t = (truth.view(-1) > 0.5).float()\n",
    "    dice = (2.0 * (p * t).sum() + eps)/ (p.sum() + t.sum() + eps)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(output, target):\n",
    "    smooth = 1e-5\n",
    "\n",
    "    if torch.is_tensor(output):\n",
    "        output = torch.sigmoid(output).data.cpu().numpy()\n",
    "    if torch.is_tensor(target):\n",
    "        target = target.data.cpu().numpy()\n",
    "    output_ = output > 0.5\n",
    "    target_ = target > 0.5\n",
    "    intersection = (output_ & target_).sum()\n",
    "    union = (output_ | target_).sum()\n",
    "\n",
    "    return (intersection + smooth) / (union + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCESoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True, w1=1, w2=1):\n",
    "        super(BCESoftDiceLoss, self).__init__()\n",
    "        self.bce_loss = nn.BCELoss(weight, size_average)\n",
    "        self.w1 = w1\n",
    "        self.w2 = w2\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        # BCELoss2d\n",
    "        probs        = torch.sigmoid(logits)\n",
    "        probs_flat   = probs.view (-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "        bce_loss = self.bce_loss(probs_flat, targets_flat)\n",
    "        \n",
    "        # SoftDiceLoss\n",
    "        num = targets.size(0)\n",
    "        probs = torch.sigmoid(logits)\n",
    "        m1  = probs.view(num,-1)\n",
    "        m2  = targets.view(num,-1)\n",
    "        intersection = (m1 * m2)\n",
    "\n",
    "        score = 2. * (intersection.sum(1)+1) / (m1.sum(1) + m2.sum(1)+1)\n",
    "        soft_dice_loss = 1- score.sum()/num\n",
    "        \n",
    "        return self.w1 * bce_loss + self.w2 * soft_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BCEDiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        bce = F.binary_cross_entropy_with_logits(input, target)\n",
    "        smooth = 1e-5\n",
    "        input = torch.sigmoid(input)\n",
    "        num = target.size(0)\n",
    "        input = input.view(num, -1)\n",
    "        target = target.view(num, -1)\n",
    "        intersection = (input * target)\n",
    "        dice = (2. * intersection.sum(1) + smooth) / (input.sum(1) + target.sum(1) + smooth)\n",
    "        dice = 1 - dice.sum() / num\n",
    "        return 0.5 * bce + dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Lovasz-Softmax and Jaccard hinge loss in PyTorch\n",
    "Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)\n",
    "\n",
    "Source:\n",
    "https://github.com/bermanmaxim/LovaszSoftmax/blob/master/pytorch/lovasz_losses.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "try:\n",
    "    from itertools import  ifilterfalse\n",
    "except ImportError: # py3k\n",
    "    from itertools import  filterfalse as ifilterfalse\n",
    "\n",
    "\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    p = len(gt_sorted)\n",
    "    gts = gt_sorted.sum()\n",
    "    intersection = gts - gt_sorted.float().cumsum(0)\n",
    "    union = gts + (1 - gt_sorted).float().cumsum(0)\n",
    "    jaccard = 1. - intersection / union\n",
    "    if p > 1: # cover 1-pixel case\n",
    "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def iou_binary(preds, labels, EMPTY=1., ignore=None, per_image=True):\n",
    "    \"\"\"\n",
    "    IoU for foreground class\n",
    "    binary: 1 foreground, 0 background\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        intersection = ((label == 1) & (pred == 1)).sum()\n",
    "        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n",
    "        if not union:\n",
    "            iou = EMPTY\n",
    "        else:\n",
    "            iou = float(intersection) / float(union)\n",
    "        ious.append(iou)\n",
    "    iou = mean(ious)    # mean accross images if per_image\n",
    "    return 100 * iou\n",
    "\n",
    "\n",
    "def iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\n",
    "    \"\"\"\n",
    "    Array of IoU for each (non ignored) class\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        iou = []\n",
    "        for i in range(C):\n",
    "            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n",
    "                intersection = ((label == i) & (pred == i)).sum()\n",
    "                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n",
    "                if not union:\n",
    "                    iou.append(EMPTY)\n",
    "                else:\n",
    "                    iou.append(float(intersection) / float(union))\n",
    "        ious.append(iou)\n",
    "    ious = [mean(iou) for iou in zip(*ious)] # mean accross images if per_image\n",
    "    return 100 * np.array(ious)\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n",
    "                          for log, lab in zip(logits, labels))\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "    if len(labels) == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return logits.sum() * 0.\n",
    "    signs = 2. * labels.float() - 1.\n",
    "    errors = (1. - logits * Variable(signs))\n",
    "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
    "    perm = perm.data\n",
    "    gt_sorted = labels[perm]\n",
    "    grad = lovasz_grad(gt_sorted)\n",
    "    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = scores.view(-1)\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = (labels != ignore)\n",
    "    vscores = scores[valid]\n",
    "    vlabels = labels[valid]\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "class StableBCELoss(torch.nn.modules.Module):\n",
    "    def __init__(self):\n",
    "         super(StableBCELoss, self).__init__()\n",
    "    def forward(self, input, target):\n",
    "        neg_abs = - input.abs()\n",
    "        loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "def binary_xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Cross entropy loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    logits, labels = flatten_binary_scores(logits, labels, ignore)\n",
    "    loss = StableBCELoss()(logits, Variable(labels.float()))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# --------------------------- MULTICLASS LOSSES ---------------------------\n",
    "\n",
    "class LovaszSoftmaxLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Class wrapper for lovasz_softmax loss function.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LovaszSoftmaxLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input = F.softmax(input, dim = 1)\n",
    "        \n",
    "        b, c, h, w = target.size()\n",
    "        labels = torch.zeros(b,h,w)\n",
    "        \n",
    "        for i in range(1, c+1):\n",
    "            labels += (target * i)[:,i-1,:,:]\n",
    "        \n",
    "        return lovasz_softmax(input, labels, classes='all')\n",
    "\n",
    "def lovasz_softmax(probas, labels, classes='present', per_image=False, ignore=None):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1).\n",
    "              Interpreted as binary (sigmoid) output with outputs of size [B, H, W].\n",
    "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class labels\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), classes=classes)\n",
    "                          for prob, lab in zip(probas, labels))\n",
    "    else:\n",
    "        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), classes=classes)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_softmax_flat(probas, labels, classes='present'):\n",
    "    \"\"\"\n",
    "    Multi-class Lovasz-Softmax loss\n",
    "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
    "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
    "      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n",
    "    \"\"\"\n",
    "    if probas.numel() == 0:\n",
    "        # only void pixels, the gradients should be 0\n",
    "        return probas * 0.\n",
    "    C = probas.size(1)\n",
    "    losses = []\n",
    "    class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes\n",
    "    for c in class_to_sum:\n",
    "        fg = (labels == c).float() # foreground for class c\n",
    "        if (classes is 'present' and fg.sum() == 0):\n",
    "            continue\n",
    "        if C == 1:\n",
    "            if len(classes) > 1:\n",
    "                raise ValueError('Sigmoid output possible only with 1 class')\n",
    "            class_pred = probas[:, 0]\n",
    "        else:\n",
    "            class_pred = probas[:, c]\n",
    "        errors = (Variable(fg) - class_pred).abs()\n",
    "        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n",
    "        perm = perm.data\n",
    "        fg_sorted = fg[perm]\n",
    "        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n",
    "    return mean(losses)\n",
    "\n",
    "\n",
    "def flatten_probas(probas, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch\n",
    "    \"\"\"\n",
    "    if probas.dim() == 3:\n",
    "        # assumes output of a sigmoid layer\n",
    "        B, H, W = probas.size()\n",
    "        probas = probas.view(B, 1, H, W)\n",
    "    B, C, H, W = probas.size()\n",
    "    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\n",
    "    labels = labels.view(-1)\n",
    "    if ignore is None:\n",
    "        return probas, labels\n",
    "    valid = (labels != ignore)\n",
    "    vprobas = probas[valid.nonzero().squeeze()]\n",
    "    vlabels = labels[valid]\n",
    "    return vprobas, vlabels\n",
    "\n",
    "def xloss(logits, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Cross entropy loss\n",
    "    \"\"\"\n",
    "    return F.cross_entropy(logits, Variable(labels), ignore_index=255)\n",
    "\n",
    "\n",
    "# --------------------------- HELPER FUNCTIONS ---------------------------\n",
    "def isnan(x):\n",
    "    return x != x\n",
    "\n",
    "\n",
    "def mean(l, ignore_nan=False, empty=0):\n",
    "    \"\"\"\n",
    "    nanmean compatible with generators.\n",
    "    \"\"\"\n",
    "    l = iter(l)\n",
    "    if ignore_nan:\n",
    "        l = ifilterfalse(isnan, l)\n",
    "    try:\n",
    "        n = 1\n",
    "        acc = next(l)\n",
    "    except StopIteration:\n",
    "        if empty == 'raise':\n",
    "            raise ValueError('Empty mean')\n",
    "        return empty\n",
    "    for n, v in enumerate(l, 2):\n",
    "        acc += v\n",
    "    if n == 1:\n",
    "        return acc\n",
    "    return acc / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_name = 'efficientnet-b4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FPN(\n",
       "  (encoder): EfficientNetEncoder(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (23): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (24): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (25): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (26): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (27): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (28): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (29): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (30): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (31): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2688, 112, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          112, 2688, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder): FPNDecoder(\n",
       "    (conv1): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (p4): FPNBlock(\n",
       "      (skip_conv): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p3): FPNBlock(\n",
       "      (skip_conv): Conv2d(56, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p2): FPNBlock(\n",
       "      (skip_conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (s5): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s4): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s3): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s2): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.2, inplace=True)\n",
       "    (final_conv): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smp.FPN(encoder_name, encoder_weights=\"imagenet\", classes=4, activation=None)\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = RAdam(model.parameters(), lr=learning_rate)\n",
    "criterion = BCEDiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = pd.DataFrame(columns = ['Epoch', \n",
    "                                      'Time per epoch', \n",
    "                                      'Avg time per step', \n",
    "                                      'Train loss',\n",
    "                                      'DICE Train',\n",
    "                                      'Test loss',\n",
    "                                     'DICE Test',\n",
    "                                     'IOU Test']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, trainloader, testloader, epochs, criterion, optimizer, train_stats):\n",
    "    #train the model\n",
    "    model = model.to(device)\n",
    "    \n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.15, patience=2)\n",
    "\n",
    "    steps = 0\n",
    "    running_loss = 0\n",
    "    dice_train = 0\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        since = time.time()\n",
    "\n",
    "        train_accuracy = 0\n",
    "        dice_train = 0\n",
    "        iou_train = 0\n",
    "        \n",
    "        for inputs, labels in tqdm_notebook(trainloader):\n",
    "            steps += 1\n",
    "            # Move input and label tensors to the default device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logps = model.forward(inputs)\n",
    "\n",
    "            loss = criterion(logps, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            dice_train += dice_channel_torch(logps, labels, threshold)\n",
    "            \n",
    "            #iou_train += iou_score(logps, labels)\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "\n",
    "        test_loss = 0\n",
    "        dice_test = 0\n",
    "        iou_test = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                logps = model.forward(inputs)\n",
    "                batch_loss = criterion(logps, labels)\n",
    "\n",
    "                test_loss += batch_loss.item()\n",
    "\n",
    "                # Calculate DICE\n",
    "                dice_test += dice_channel_torch(logps, labels, threshold)\n",
    "                \n",
    "                iou_test += iou_score(logps, labels)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "              f\"Time per epoch: {time_elapsed:.4f}.. \"\n",
    "              f\"Average time per step: {time_elapsed/len(trainloader):.4f}.. \"\n",
    "              f\"Train loss: {running_loss/len(trainloader):.4f}.. \"\n",
    "              f\"Test loss: {test_loss/len(testloader):.4f}.. \"\n",
    "              f\"DICE Train: {dice_train/len(trainloader):.4f}.. \"\n",
    "              f\"DICE Test: {dice_test/len(testloader):.4f}.. \"\n",
    "              #f\"IOU Train: {iou_train/len(trainloader):.4f}.. \"\n",
    "              f\"IOU Test: {iou_test/len(testloader):.4f}.. \"\n",
    "             )\n",
    "\n",
    "        train_stats = train_stats.append({'Epoch': epoch + 1, \n",
    "                                          'Time per epoch':time_elapsed, \n",
    "                                          'Avg time per step': time_elapsed/len(trainloader), \n",
    "                                          'Train loss' : running_loss/len(trainloader),\n",
    "                                          'Test loss' : test_loss/len(testloader),\n",
    "                                          'DICE Train' : dice_train/len(trainloader),\n",
    "                                          'DICE Test' : dice_test/len(testloader),\n",
    "                                          'IOU Test' : iou_test/len(testloader)\n",
    "                                         }, \n",
    "                                         ignore_index=True)\n",
    "                \n",
    "        scheduler.step(test_loss/len(testloader))\n",
    "        running_loss = 0\n",
    "        model.train()\n",
    "        \n",
    "    return model, train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b8d71ad8e5457db6f3405af9e85fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10.. Time per epoch: 701.1222.. Average time per step: 0.5578.. Train loss: 0.7150.. Test loss: 0.4641.. DICE Train: 0.8872.. DICE Test: 0.9066.. IOU Test: 0.6142.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a4788b31d84822a41c89bc536642e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10.. Time per epoch: 691.5406.. Average time per step: 0.5502.. Train loss: 0.7082.. Test loss: 0.4715.. DICE Train: 0.8837.. DICE Test: 0.9013.. IOU Test: 0.5974.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe688867e88344df8d64cf934b14b67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10.. Time per epoch: 689.0533.. Average time per step: 0.5482.. Train loss: 0.7149.. Test loss: 0.4719.. DICE Train: 0.8860.. DICE Test: 0.9011.. IOU Test: 0.5916.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308b2be88cf0484ea4af2e04f19ceea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10.. Time per epoch: 688.6285.. Average time per step: 0.5478.. Train loss: 0.7181.. Test loss: 0.4705.. DICE Train: 0.8837.. DICE Test: 0.9013.. IOU Test: 0.5936.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c94f96000659438dab0c3430d5c23cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10.. Time per epoch: 685.5536.. Average time per step: 0.5454.. Train loss: 0.7140.. Test loss: 0.4724.. DICE Train: 0.8851.. DICE Test: 0.8994.. IOU Test: 0.5907.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e286c16f62b4b3996b7f55f4ae11b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 7/10.. Time per epoch: 689.4718.. Average time per step: 0.5485.. Train loss: 0.7151.. Test loss: 0.4688.. DICE Train: 0.8863.. DICE Test: 0.9038.. IOU Test: 0.6065.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b7959301514c6db1164c698c2e5411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10.. Time per epoch: 774.2982.. Average time per step: 0.6160.. Train loss: 0.7232.. Test loss: 0.4633.. DICE Train: 0.8840.. DICE Test: 0.9017.. IOU Test: 0.5985.. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8deda9b0e3490393bff7f3541470f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1257), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "model.train()\n",
    "model, train_stats = train_model(model, device, trainloader, testloader, epochs, criterion, optimizer, train_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'efficientnet_b4_dice_' + str(epochs) + '_resampled.pth'\n",
    "\n",
    "checkpoint = {'state_dict': model.state_dict()}\n",
    "\n",
    "torch.save(checkpoint, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training stats\n",
    "train_stats.to_csv('efficientnet_b4_bcedice_stats_resampled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_stats['Test loss'], label=\"test\")\n",
    "plt.plot(train_stats['Train loss'], label=\"train\")\n",
    "plt.ylim(0, 1.4)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_stats['DICE Train'], label=\"test\")\n",
    "plt.plot(train_stats['DICE Test'], label=\"train\")\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"dice\")\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fa5b6855d24f638a8d332c716c4997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=315), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "dice_test = 0\n",
    "iou = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm_notebook(testloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logps = model.forward(inputs)\n",
    "        batch_loss = criterion(logps, labels)\n",
    "\n",
    "        test_loss += batch_loss.item()\n",
    "\n",
    "        # Calculate DICE\n",
    "        dice_test += dice_channel_torch(logps, labels, threshold)\n",
    "        \n",
    "        iou += iou_score(logps, labels)\n",
    "        \n",
    "test_loss = test_loss / len(testloader)\n",
    "dice_test = dice_test / len(testloader)\n",
    "iou = iou / len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.461808552155419\n",
      "DICE test: 0.9034254550933838\n",
      "IOU test: 0.611923679900113\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: {}'.format(test_loss))\n",
    "print('DICE test: {}'.format(dice_test))\n",
    "print('IOU test: {}'.format(iou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FPN(\n",
       "  (encoder): EfficientNetEncoder(\n",
       "    (_conv_stem): Conv2dStaticSamePadding(\n",
       "      3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "    )\n",
       "    (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "    (_blocks): ModuleList(\n",
       "      (0): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): MBConvBlock(\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (6): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (7): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (8): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (9): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (10): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (11): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (12): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (13): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (14): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (15): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (16): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (17): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (18): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (19): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (20): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (21): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (22): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (23): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (24): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (25): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (26): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (27): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (28): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (29): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (30): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (31): MBConvBlock(\n",
       "        (_expand_conv): Conv2dStaticSamePadding(\n",
       "          448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "          2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n",
       "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "        )\n",
       "        (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "        (_se_reduce): Conv2dStaticSamePadding(\n",
       "          2688, 112, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_se_expand): Conv2dStaticSamePadding(\n",
       "          112, 2688, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_project_conv): Conv2dStaticSamePadding(\n",
       "          2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (static_padding): Identity()\n",
       "        )\n",
       "        (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (_conv_head): Conv2dStaticSamePadding(\n",
       "      448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "      (static_padding): Identity()\n",
       "    )\n",
       "    (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder): FPNDecoder(\n",
       "    (conv1): Conv2d(448, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (p4): FPNBlock(\n",
       "      (skip_conv): Conv2d(160, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p3): FPNBlock(\n",
       "      (skip_conv): Conv2d(56, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (p2): FPNBlock(\n",
       "      (skip_conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (s5): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s4): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s3): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (s2): SegmentationBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv3x3GNReLU(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.2, inplace=True)\n",
       "    (final_conv): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/paulorzp/rle-functions-run-lenght-encode-decode\n",
    "def mask2rle(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels= img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    '''Dataset for test prediction'''\n",
    "    def __init__(self, root, df, mean, std):\n",
    "        self.root = root\n",
    "        df['ImageId'] = df['ImageId_ClassId'].apply(lambda x: x.split('_')[0])\n",
    "        self.fnames = df['ImageId'].unique().tolist()\n",
    "        self.num_samples = len(self.fnames)\n",
    "        self.transform = Compose(\n",
    "            [\n",
    "                Normalize(mean=mean, std=std, p=1),\n",
    "                ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.fnames[idx]\n",
    "        path = os.path.join(self.root, fname)\n",
    "        image = cv2.imread(path)\n",
    "        images = self.transform(image=image)[\"image\"]\n",
    "        return fname, images\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "sample_submission_path = './severstal-steel-defect-detection/sample_submission.csv'\n",
    "test_data_folder = TEST_PATH\n",
    "df = pd.read_csv(sample_submission_path)\n",
    "testset = DataLoader(\n",
    "    TestDataset(test_data_folder, df, mean, std),\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(probability, threshold, min_size):\n",
    "    '''Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored'''\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((256, 1600), np.float32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebca147ea8d24141b00fc93bf107b3fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=901), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_threshold = threshold\n",
    "min_size = 3500\n",
    "\n",
    "# start prediction\n",
    "predictions = []\n",
    "for i, batch in enumerate(tqdm_notebook(testset)):\n",
    "    fnames, images = batch\n",
    "    batch_preds = torch.sigmoid(model(images.to(device)))\n",
    "    batch_preds = batch_preds.detach().cpu().numpy()\n",
    "    for fname, preds in zip(fnames, batch_preds):\n",
    "        for cls, pred in enumerate(preds):\n",
    "            pred, num = post_process(pred, best_threshold, min_size)\n",
    "            rle = mask2rle(pred)\n",
    "            name = fname + f\"_{cls+1}\"\n",
    "            predictions.append([name, rle])\n",
    "\n",
    "# save predictions to submission.csv\n",
    "df = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])\n",
    "df.to_csv(\"submission_resampled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId_ClassId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>004f40c73.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>004f40c73.jpg_2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>004f40c73.jpg_3</td>\n",
       "      <td>17293 7 17547 14 17802 20 18058 43 18314 45 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>004f40c73.jpg_4</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>006f39c41.jpg_1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId_ClassId                                      EncodedPixels\n",
       "0  004f40c73.jpg_1                                                   \n",
       "1  004f40c73.jpg_2                                                   \n",
       "2  004f40c73.jpg_3  17293 7 17547 14 17802 20 18058 43 18314 45 18...\n",
       "3  004f40c73.jpg_4                                                   \n",
       "4  006f39c41.jpg_1                                                   "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7204"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.EncodedPixels.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
